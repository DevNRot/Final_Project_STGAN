{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This code was written by Devorah Rotman 316472026 and Carmit Kaye 346038169"
  },
  {
   "cell_type": "code",
   "source": [
    "MONET_PATH = '../data/monet_jpg'\n",
    "PHOTO_PATH = '../data/photo_jpg'"
   ],
   "metadata": {
    "id": "mHiXS7zo3Njc",
    "ExecuteTime": {
     "end_time": "2025-07-01T18:38:36.612419Z",
     "start_time": "2025-07-01T18:38:36.609724Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "hBPCT1eS2tBv",
    "ExecuteTime": {
     "end_time": "2025-07-01T18:38:39.394883Z",
     "start_time": "2025-07-01T18:38:36.630794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torchvision import models\n",
    "from STGAN.Data_loader_STGAN import get_content_loader, get_style_loader\n",
    "from STGAN.models_STGAN import Discriminator, Generator\n",
    "from STGAN.utils import visualize_output, visualize_graphs\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Training:\n",
    "    def __init__(self,\n",
    "                 content_path,\n",
    "                 style_path,\n",
    "                 batch_size,\n",
    "                 in_style,\n",
    "                 channels,\n",
    "                 epochs,\n",
    "                 lr_gen,\n",
    "                 #lr_style,\n",
    "                 lr_dis,\n",
    "                 ckpt_path,\n",
    "                 device,\n",
    "                 pretrained):\n",
    "\n",
    "        self.device = device\n",
    "        self.in_style = in_style\n",
    "        self.content_loader = get_content_loader(content_path, batch_size)\n",
    "        self.style_loader = get_style_loader(style_path, batch_size)\n",
    "        self.content_iter = iter(self.content_loader)\n",
    "        self.style_iter = iter(self.style_loader)\n",
    "\n",
    "        self.dis = Discriminator(channels).to(device)\n",
    "        self.gen = Generator(in_style, channels).to(device)\n",
    "        #self.lambda_gp = 10\n",
    "\n",
    "        #style_params = [self.gen.w]\n",
    "        #gen_params = [p for n, p in self.gen.named_parameters() if not n.startswith(\"w.\")]\n",
    "        #style_params = list(self.gen.style_mapper.parameters())\n",
    "        #gen_params = [p for n, p in self.gen.named_parameters() if not n.startswith(\"style_mapper\")]\n",
    "        self.gen_opt = torch.optim.Adam(self.gen.parameters(), lr=lr_gen, betas=(0.9, 0.999))\n",
    "        self.dis_opt = torch.optim.Adam(self.dis.parameters(), lr=lr_dis, betas=(0.9, 0.999))\n",
    "        #self.style_opt = torch.optim.Adam(self.gen.parameters(), lr=lr_style, betas=(0.9, 0.999))\n",
    "        self.grow_rank = 0\n",
    "        self.max_scale = len(channels)-1\n",
    "        self.ckpt_path = ckpt_path if ckpt_path[-3:] == '.pt' else os.path.join(ckpt_path, 'last.pt')\n",
    "        self.pretrained = pretrained\n",
    "        self.lr_gen = lr_gen\n",
    "        self.lr_dis = lr_dis\n",
    "        #self.lr_style = lr_style\n",
    "        self.epochs = epochs\n",
    "        self.alpha = 0\n",
    "\n",
    "        # Load pretrained VGG19s\n",
    "        self.vgg = models.vgg19(pretrained=True).features[:21].to(device).eval()\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vgg_input = models.vgg19(pretrained=True).features.to(device).eval()\n",
    "        for param in self.vgg_input.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.content_loss_weight = 1  # Adjust to control content preservation strength\n",
    "\n",
    "        if self.pretrained:\n",
    "            self.load_ckpts_train()\n",
    "\n",
    "    def compute_content_loss(self, real_img, generated_img):\n",
    "        # Resize to 128x128 as expected by VGG\n",
    "        real_img = F.interpolate(real_img, size=(128,128), mode='bilinear', align_corners=False)\n",
    "        generated_img = F.interpolate(generated_img, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Normalize for VGG\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406], device=self.device).view(1, 3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225], device=self.device).view(1, 3, 1, 1)\n",
    "        gen_norm = (generated_img - mean) / std\n",
    "\n",
    "        real_feat = self.vgg(real_img)\n",
    "        gen_feat = self.vgg(gen_norm)\n",
    "\n",
    "        return F.mse_loss(gen_feat, real_feat)\n",
    "\n",
    "    def train_loop(self):\n",
    "        #define everything needed to smoothen alpha\n",
    "        trick = 1\n",
    "        steps_per_epoch = len(self.content_loader)\n",
    "        num_epochs = self.epochs[self.grow_rank]\n",
    "        #total_steps = steps_per_epoch * num_epochs\n",
    "        #alpha_transition_steps = total_steps // 2\n",
    "        alpha_p = int(0.5*num_epochs)\n",
    "\n",
    "        generator_loss_list = []\n",
    "        discriminator_loss_list = []\n",
    "\n",
    "        #current_step = 0\n",
    "        freeze_d = (self.grow_rank >= 3)\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            dis_total_loss = 0\n",
    "            gen_total_loss = 0\n",
    "            content_total_loss = 0\n",
    "            adv_total_loss = 0\n",
    "\n",
    "            for i in tqdm(range(len(self.content_loader)), ascii=True, desc=f\"Epoch {epoch+1} Training\"):\n",
    "                try:\n",
    "                    content_imgs, _ = next(self.content_iter)\n",
    "                except StopIteration:\n",
    "                    self.content_iter = iter(self.content_loader)\n",
    "                    content_imgs, _ = next(self.content_iter)\n",
    "\n",
    "                try:\n",
    "                    style_imgs, _ = next(self.style_iter)\n",
    "                except StopIteration:\n",
    "                    self.style_iter = iter(self.style_loader)\n",
    "                    style_imgs, _ = next(self.style_iter)\n",
    "\n",
    "                content_imgs = content_imgs.to(self.device)\n",
    "                style_imgs = style_imgs.to(self.device)\n",
    "                self.alpha = min(1, trick/alpha_p*len(self.content_loader)) if self.grow_rank >0 else 1\n",
    "                #self.alpha = min(1.0, current_step / alpha_transition_steps) if self.grow_rank >0 else 1\n",
    "\n",
    "                ##### Extract features from VGG layer 36 #####\n",
    "                # Resize and normalize\n",
    "                new_input = F.interpolate(content_imgs, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    x = new_input\n",
    "                    vgg_feat = self.vgg_input(x)\n",
    "                #print(vgg_feat.shape)\n",
    "\n",
    "                ##### Train Discriminator #####\n",
    "                #if not freeze_d or trick > 1000:\n",
    "                if not freeze_d or trick > 0:\n",
    "                    for p in self.dis.parameters():\n",
    "                        p.requires_grad = True\n",
    "                else:\n",
    "                    for p in self.dis.parameters():\n",
    "                        p.requires_grad = False\n",
    "\n",
    "                self.dis_opt.zero_grad()\n",
    "\n",
    "                fake_imgs = self.gen(vgg_feat, alpha = self.alpha).detach()\n",
    "\n",
    "                #make sure that the fake images and the real images inputted into the discriminator have the same size\n",
    "                target_size = fake_imgs.shape[2:]  # (H, W)\n",
    "                if style_imgs.shape[2:] != target_size:\n",
    "                    style_imgs = F.interpolate(style_imgs, size=target_size, mode='bilinear', align_corners=False)\n",
    "\n",
    "                real_pred = self.dis(style_imgs, alpha = self.alpha)\n",
    "                fake_pred = self.dis(fake_imgs, alpha = self.alpha)\n",
    "\n",
    "                #WGAN loss\n",
    "                #fake_pred_loss = torch.mean(fake_pred)\n",
    "                #real_pred_loss = torch.mean(-real_pred)\n",
    "                #gradient_penalty = self.calculate_gradient_penalty(style_imgs, fake_imgs)\n",
    "                #d_loss = fake_pred_loss + real_pred_loss + self.lambda_gp * gradient_penalty\n",
    "                #end of WGAN loss\n",
    "\n",
    "                #loss version 2\n",
    "                fake_pred_loss = F.softplus(fake_pred).mean()\n",
    "                real_pred_loss = F.softplus(-real_pred).mean()\n",
    "                d_loss = fake_pred_loss + real_pred_loss\n",
    "                #end of loss v2\n",
    "\n",
    "                d_loss.backward()\n",
    "                self.dis_opt.step()\n",
    "\n",
    "                dis_total_loss += d_loss.item()\n",
    "\n",
    "                ##### Train Generator #####\n",
    "                #perc_content = 0.95 #fraction of the epochs used to train the content only\n",
    "                style_lss_weight = 0.5*trick/(steps_per_epoch * num_epochs)\n",
    "                for _ in range(2):\n",
    "\n",
    "                    self.gen_opt.zero_grad()\n",
    "                    fake_imgs = self.gen(vgg_feat, alpha = self.alpha)\n",
    "                    fake_pred = self.dis(fake_imgs, alpha = self.alpha)\n",
    "                    content_loss = self.compute_content_loss(content_imgs, fake_imgs)\n",
    "                    c_loss = self.content_loss_weight * content_loss\n",
    "                    adv_loss = F.softplus(-fake_pred).mean()\n",
    "                    a_loss = style_lss_weight * adv_loss\n",
    "\n",
    "                    full_loss = a_loss+c_loss\n",
    "                    full_loss.backward()\n",
    "\n",
    "\n",
    "                    self.gen_opt.step()\n",
    "                    gen_total_loss +=  a_loss.item() + c_loss.item()\n",
    "                    adv_total_loss += a_loss.item()\n",
    "                    content_total_loss += c_loss.item()\n",
    "\n",
    "\n",
    "                trick += 1\n",
    "                #current_step += 1\n",
    "\n",
    "            #log the gen and dis losses\n",
    "            gen_total_loss = gen_total_loss / steps_per_epoch\n",
    "            adv_total_loss = adv_total_loss / steps_per_epoch\n",
    "            content_total_loss = content_total_loss / steps_per_epoch\n",
    "            dis_total_loss = dis_total_loss / steps_per_epoch\n",
    "            generator_loss_list.append(gen_total_loss)\n",
    "            discriminator_loss_list.append(dis_total_loss)\n",
    "            print(f\"Epoch {epoch+1}:\",\n",
    "                  f\"GPU Mem = {round(torch.cuda.memory_reserved()/1E9, 3)} GB |\",\n",
    "                  f\"D loss = {round(dis_total_loss, 3)} |\",\n",
    "                  f\"Content loss = {round(content_total_loss, 3)}|\",\n",
    "                  f\"Adv loss = {round(adv_total_loss, 3)}|\",\n",
    "                  f\"G loss = {round(gen_total_loss, 3)}\")\n",
    "\n",
    "\n",
    "            self.save_model()\n",
    "        return generator_loss_list, discriminator_loss_list\n",
    "\n",
    "    def train(self):\n",
    "        while True:\n",
    "            generator_loss_list, discriminator_loss_list = self.train_loop()\n",
    "            print(f\"the final samples from scale {self.grow_rank+1}\")\n",
    "\n",
    "            # Generate fake image using a random content image\n",
    "            content_imgs, _ = next(iter(self.content_loader))\n",
    "            content_imgs = content_imgs.to(self.device)\n",
    "\n",
    "            # Preprocess for VGG\n",
    "            new_input = F.interpolate(content_imgs, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x = new_input\n",
    "                vgg_feat = self.vgg_input(x)\n",
    "\n",
    "            visualize_output(new_input, f\"original_content_ims_{self.grow_rank}\")\n",
    "            cosine_distance = F.cosine_similarity(vgg_feat[0], vgg_feat[1]).mean()\n",
    "            print(cosine_distance)\n",
    "\n",
    "            fake_imgs = self.gen(vgg_feat, alpha=self.alpha)\n",
    "            visualize_output(fake_imgs, self.grow_rank)\n",
    "            visualize_graphs(generator_loss_list, discriminator_loss_list, self.grow_rank)\n",
    "            if self.grow_rank+1 == self.max_scale:\n",
    "                print(\"Maximum scale has been reached.\")\n",
    "                break\n",
    "            continue_training = self.grow()\n",
    "\n",
    "    def load_ckpts_train(self):\n",
    "        ckpt = torch.load(self.ckpt_path, map_location=self.device)\n",
    "        for i in range(ckpt['grow_rank']):\n",
    "            self.grow()\n",
    "        self.gen.load_state_dict(ckpt['generator'])\n",
    "        self.dis.load_state_dict(ckpt['discriminator'])\n",
    "        self.gen_opt.load_state_dict(ckpt['generator_opt'])\n",
    "        self.dis_opt.load_state_dict(ckpt['discriminator_opt'])\n",
    "        self.grow_rank = ckpt['grow_rank']\n",
    "        del ckpt\n",
    "\n",
    "    def grow(self):\n",
    "        torch.cuda.empty_cache()\n",
    "        self.gen.grow()\n",
    "        self.dis.grow()\n",
    "        self.gen.cuda()\n",
    "        self.dis.cuda()\n",
    "        self.grow_rank += 1\n",
    "        #gen_params = [p for n, p in self.gen.named_parameters() if not n.startswith(\"w.\")]\n",
    "        #gen_params = [p for n, p in self.gen.named_parameters() if not n.startswith(\"style_mapper\")]\n",
    "        self.gen_opt = torch.optim.Adam(self.gen.parameters(), lr=self.lr_gen*0.7**self.grow_rank, betas=(0.9, 0.999))\n",
    "        #self.style_opt = torch.optim.Adam(self.gen.parameters(), lr=self.lr_style*0.7**self.grow_rank, betas=(0.9, 0.999))\n",
    "        self.dis_opt = torch.optim.Adam(self.dis.parameters(), lr=self.lr_dis*0.7**self.grow_rank, betas=(0.9, 0.999))\n",
    "\n",
    "    def save_model(self):\n",
    "        ckpt = {\n",
    "            'generator': self.gen.state_dict(),\n",
    "            'discriminator': self.dis.state_dict(),\n",
    "            'generator_opt': self.gen_opt.state_dict(),\n",
    "            'discriminator_opt': self.dis_opt.state_dict(),\n",
    "            'grow_rank': self.grow_rank\n",
    "        }\n",
    "        torch.save(ckpt, self.ckpt_path)\n",
    "        del ckpt\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "IxEscPslaQuD",
    "outputId": "a86be98c-6d2e-4120-8ca2-6fa122719fe1",
    "ExecuteTime": {
     "end_time": "2025-07-01T21:08:28.496264Z",
     "start_time": "2025-07-01T18:38:39.456212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content_ims_folder = PHOTO_PATH\n",
    "style_ims_folder = MONET_PATH\n",
    "batch_size = 8\n",
    "in_style = 512 #size of w\n",
    "channels = [512, 512, 512, 256, 128, 64, 32] # layer channel sizes\n",
    "lr_gen = 0.007\n",
    "lr_dis = 0.00001\n",
    "epochs = [6,10,10,18,20,24]\n",
    "checkpoint_path = 'C:/Users/dnrot/OneDrive/Desktop/BGU MSc/HW_deb/DLIP/final_project/STGAN/checkpoints'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained = True\n",
    "\n",
    "\n",
    "\n",
    "Trainer = Training(content_ims_folder, style_ims_folder, batch_size, in_style, channels, epochs, lr_gen, lr_dis, checkpoint_path, device, pretrained)\n",
    "Trainer.train()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|##########| 879/879 [06:22<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: GPU Mem = 1.424 GB | D loss = 0.031 | Content loss = 17.656| Adv loss = 0.108| G loss = 17.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|##########| 879/879 [06:53<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: GPU Mem = 1.424 GB | D loss = 0.022 | Content loss = 17.459| Adv loss = 0.333| G loss = 17.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|##########| 879/879 [06:46<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: GPU Mem = 1.424 GB | D loss = 0.021 | Content loss = 17.351| Adv loss = 0.563| G loss = 17.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|##########| 879/879 [06:36<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: GPU Mem = 1.424 GB | D loss = 0.025 | Content loss = 17.273| Adv loss = 0.79| G loss = 18.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|##########| 879/879 [06:39<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: GPU Mem = 1.424 GB | D loss = 0.03 | Content loss = 17.203| Adv loss = 0.998| G loss = 18.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|##########| 879/879 [06:51<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: GPU Mem = 1.424 GB | D loss = 0.035 | Content loss = 17.149| Adv loss = 1.203| G loss = 18.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|##########| 879/879 [06:47<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: GPU Mem = 1.424 GB | D loss = 0.039 | Content loss = 17.103| Adv loss = 1.39| G loss = 18.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|##########| 879/879 [06:48<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: GPU Mem = 1.424 GB | D loss = 0.04 | Content loss = 17.06| Adv loss = 1.582| G loss = 18.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|##########| 879/879 [06:43<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: GPU Mem = 1.424 GB | D loss = 0.042 | Content loss = 17.026| Adv loss = 1.767| G loss = 18.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|##########| 879/879 [06:49<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: GPU Mem = 1.424 GB | D loss = 0.044 | Content loss = 16.994| Adv loss = 1.955| G loss = 18.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100%|##########| 879/879 [06:48<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: GPU Mem = 1.424 GB | D loss = 0.045 | Content loss = 16.968| Adv loss = 2.129| G loss = 19.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100%|##########| 879/879 [06:11<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: GPU Mem = 1.424 GB | D loss = 0.048 | Content loss = 16.973| Adv loss = 2.315| G loss = 19.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100%|##########| 879/879 [06:30<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: GPU Mem = 1.424 GB | D loss = 0.051 | Content loss = 16.951| Adv loss = 2.486| G loss = 19.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100%|##########| 879/879 [06:47<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: GPU Mem = 1.424 GB | D loss = 0.057 | Content loss = 16.944| Adv loss = 2.649| G loss = 19.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100%|##########| 879/879 [05:35<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: GPU Mem = 1.424 GB | D loss = 0.06 | Content loss = 16.956| Adv loss = 2.783| G loss = 19.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 100%|##########| 879/879 [05:53<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: GPU Mem = 1.424 GB | D loss = 0.063 | Content loss = 16.977| Adv loss = 2.925| G loss = 19.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 100%|##########| 879/879 [05:44<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: GPU Mem = 1.424 GB | D loss = 0.067 | Content loss = 17.002| Adv loss = 3.05| G loss = 20.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 100%|##########| 879/879 [05:34<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: GPU Mem = 1.424 GB | D loss = 0.072 | Content loss = 17.044| Adv loss = 3.181| G loss = 20.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 100%|##########| 879/879 [05:32<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: GPU Mem = 1.424 GB | D loss = 0.071 | Content loss = 17.114| Adv loss = 3.332| G loss = 20.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training: 100%|##########| 879/879 [05:32<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: GPU Mem = 1.424 GB | D loss = 0.077 | Content loss = 17.177| Adv loss = 3.43| G loss = 20.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training: 100%|##########| 879/879 [05:28<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: GPU Mem = 1.424 GB | D loss = 0.082 | Content loss = 17.264| Adv loss = 3.578| G loss = 20.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training: 100%|##########| 879/879 [05:24<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: GPU Mem = 1.424 GB | D loss = 0.086 | Content loss = 17.347| Adv loss = 3.717| G loss = 21.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training: 100%|##########| 879/879 [05:19<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: GPU Mem = 1.424 GB | D loss = 0.098 | Content loss = 17.446| Adv loss = 3.842| G loss = 21.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training: 100%|##########| 879/879 [05:19<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: GPU Mem = 1.424 GB | D loss = 0.098 | Content loss = 17.561| Adv loss = 3.999| G loss = 21.56\n",
      "the final samples from scale 6\n",
      "tensor(0.0795, device='cuda:0')\n",
      "Maximum scale has been reached.\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ]
}
